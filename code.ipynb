{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea6bed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from plyfile import PlyData, PlyElement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2605aa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def image_derivatives(image):\n",
    "        kernel = np.array([-1, 0, 1])\n",
    "        Ix = cv2.filter2D(image, -1, kernel)\n",
    "        Iy = cv2.filter2D(image, -1, kernel.T)\n",
    "        return Ix, Iy\n",
    "\n",
    "\n",
    "    def gaussian_smoothing(derivatives):\n",
    "        kernel = cv2.getGaussianKernel(5, -1)\n",
    "        Ix_smoothed = cv2.sepFilter2D(derivatives[0], -1, kernel, kernel.T)\n",
    "        Iy_smoothed = cv2.sepFilter2D(derivatives[1], -1, kernel, kernel.T)\n",
    "        return Ix_smoothed, Iy_smoothed\n",
    "\n",
    "\n",
    "    def harris_response(Ix_smoothed, Iy_smoothed):\n",
    "        Ixx = Ix_smoothed**2\n",
    "        Iyy = Iy_smoothed**2\n",
    "        Ixy = Ix_smoothed * Iy_smoothed\n",
    "\n",
    "        det_M = Ixx * Iyy - Ixy**2\n",
    "        trace_M = Ixx + Iyy\n",
    "        k = 0.04\n",
    "\n",
    "        return det_M - k * trace_M**2\n",
    "\n",
    "    def non_maximum_suppression(harris_response):\n",
    "        response_filtered = cv2.dilate(harris_response, np.ones((3, 3)))\n",
    "        maxima = (harris_response == response_filtered)\n",
    "        return maxima\n",
    "\n",
    "\n",
    "    def strongest_corners(harris_response, maxima, num_corners=100):\n",
    "        harris_max = harris_response * maxima\n",
    "        idx = np.argsort(harris_max.ravel())[::-1][:num_corners]\n",
    "        return np.column_stack(np.unravel_index(idx, harris_response.shape))\n",
    "\n",
    "\n",
    "#     def corners_to_3D_points(corners, depth_map, K, S=5000):\n",
    "#         num_corners = corners.shape[0]\n",
    "#         points_3D = np.zeros((num_corners, 3))\n",
    "\n",
    "#         for i, (x, y) in enumerate(corners):\n",
    "#             d = depth_map[y, x]\n",
    "#             if d == 0:\n",
    "#                 continue\n",
    "#             point_2D = np.array([x, y, 1])\n",
    "#             point_3D = d / S * np.linalg.inv(K) @ point_2D\n",
    "#             points_3D[i] = point_3D\n",
    "\n",
    "#         valid_points = points_3D[~np.all(points_3D == 0, axis=1)]\n",
    "#         return valid_points\n",
    "\n",
    "#         def corners_to_3D_points(corners, depth_map, K, S=5000):\n",
    "#             inverse_k = np.linalg.inv(K)\n",
    "#             _3d_points = {}\n",
    "#             for corner in corners:\n",
    "#                 x, y = corner\n",
    "#                 d = depth[x, y]\n",
    "#                 if d == 0:\n",
    "#                     continue\n",
    "#                 harris_2d = [y, x, 1]\n",
    "#                 r = (1/s) * d * np.dot(inverse_k, harris_2d)\n",
    "#                 valid_points[corner] = r\n",
    "\n",
    "#             return valid_points\n",
    "\n",
    "    def corners_to_3D_points(corners, depth_map, K, S=1):\n",
    "        points = []\n",
    "        fx, fy, cx, cy = K[0, 0], K[1, 1], K[0, 2], K[1, 2]\n",
    "        for corner in corners:\n",
    "            x, y = corner\n",
    "            d = depth_map[y, x]  # Corrected variable access from 'depth_map[x, y]' to 'depth_map[y, x]'\n",
    "            if d == 0:\n",
    "                continue\n",
    "            X = (x - cx) * d / fx\n",
    "            Y = (y - cy) * d / fy\n",
    "            Z = d\n",
    "            points.append([X, Y, Z])\n",
    "        return np.array(points) * S\n",
    "\n",
    "\n",
    "    def rank_transform(image, window_size=5):\n",
    "        half_window = window_size // 2\n",
    "        img_padded = cv2.copyMakeBorder(image, half_window, half_window, half_window, half_window, cv2.BORDER_REFLECT)\n",
    "        ranks = np.zeros_like(image, dtype=np.uint8)\n",
    "\n",
    "        for y in range(image.shape[0]):\n",
    "            for x in range(image.shape[1]):\n",
    "                window = img_padded[y:y + window_size, x:x + window_size]\n",
    "                ranks[y, x] = np.sum(window < window[half_window, half_window])\n",
    "\n",
    "        return ranks\n",
    "\n",
    "    def compute_distances(corners1, corners2, rank1, rank2, window_size=11):\n",
    "        half_window = window_size // 2\n",
    "        num_corners1, num_corners2 = corners1.shape[0], corners2.shape[0]\n",
    "        distances = np.zeros((num_corners2, num_corners1), dtype=np.float32)\n",
    "        rank1_padded = cv2.copyMakeBorder(rank1, half_window, half_window, half_window, half_window, cv2.BORDER_REFLECT)\n",
    "        rank2_padded = cv2.copyMakeBorder(rank2, half_window, half_window, half_window, half_window, cv2.BORDER_REFLECT)\n",
    "\n",
    "        for i, (y2, x2) in enumerate(corners2):\n",
    "            for j, (y1, x1) in enumerate(corners1):\n",
    "                window1 = rank1_padded[y1:y1 + window_size, x1:x1 + window_size]\n",
    "                window2 = rank2_padded[y2:y2 + window_size, x2:x2 + window_size]\n",
    "                distances[i, j] = np.sum(np.abs(window1 - window2))\n",
    "\n",
    "        return distances\n",
    "    \n",
    "    def find_best_matches(distances, threshold=0.7):\n",
    "        matches = []\n",
    "        for i in range(distances.shape[1]):\n",
    "            min_idx = np.argmin(distances[:, i])\n",
    "            min_val = distances[min_idx, i]\n",
    "            distances[min_idx, i] = np.inf\n",
    "            second_min_val = distances[:, i].min()\n",
    "\n",
    "            if min_val < threshold * second_min_val:\n",
    "                matches.append((min_idx, i))\n",
    "\n",
    "        return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "303795a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pose Estimation:\n",
    "\n",
    "def estimate_pose(matches, points1_3D, points2_3D):\n",
    "    num_matches = len(matches)\n",
    "    P1 = np.zeros((num_matches, 3))\n",
    "    P2 = np.zeros((num_matches, 3))\n",
    "\n",
    "    for i, (pt2, pt1) in enumerate(matches):\n",
    "        P1[i] = points1_3D[pt2]\n",
    "        P2[i] = points2_3D[pt1]\n",
    "\n",
    "    mean1, mean2 = np.mean(P1, axis=0), np.mean(P2, axis=0)\n",
    "    P1_centered, P2_centered = P1 - mean1, P2 - mean2\n",
    "  \n",
    "    W = P2_centered.T @ P1_centered\n",
    "    U, _, Vt = np.linalg.svd(W)\n",
    "    R = U @ Vt\n",
    "    t = mean1 - R @ mean2\n",
    "\n",
    "    return R, t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8800ec14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Part 5: Finis Coronat Opus\n",
    "def transform_points(points, R, t):\n",
    "\n",
    "    points_hom = np.hstack((points, np.ones((points.shape[0], 1))))\n",
    "    #transformed_points_hom = R @ points_hom.T + t[:3, None]\n",
    "    transformed_points_hom = R @ points_hom[:, :3].T + t[:3, None]\n",
    "    #transformed_points = (transformed_points_hom / transformed_points_hom[-1, :])[:3, :].T\n",
    "    epsilon = 1e-8\n",
    "    transformed_points = (transformed_points_hom / (transformed_points_hom[-1, :] + epsilon))[:3, :].T\n",
    "\n",
    "    return transformed_points\n",
    "\n",
    "def get_colored_3d_points(image, depth_map, K, S=5000):\n",
    "    height, width, _ = image.shape\n",
    "    points_3d = np.zeros((height, width, 3))\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            d = depth_map[y, x]\n",
    "            if d == 0:\n",
    "                continue\n",
    "            point_2d = np.array([x, y, 1])\n",
    "            point_3d = d / S * np.linalg.inv(K) @ point_2d\n",
    "            points_3d[y, x] = point_3d\n",
    "    valid_points = points_3d[~np.all(points_3d == 0, axis=2)]\n",
    "    valid_colors = image[~np.all(points_3d == 0, axis=2)]\n",
    "    return valid_points, valid_colors\n",
    "\n",
    "# Load the images\n",
    "image1 = cv2.imread(\"rgb1.png\")\n",
    "image2 = cv2.imread(\"rgb2.png\")\n",
    "image3 = cv2.imread(\"rgb3.png\")\n",
    "\n",
    "depth1 = cv2.imread(\"depth1.png\", cv2.IMREAD_ANYDEPTH)\n",
    "depth2 = cv2.imread(\"depth2.png\", cv2.IMREAD_ANYDEPTH)\n",
    "depth3 = cv2.imread(\"depth3.png\", cv2.IMREAD_ANYDEPTH)\n",
    "\n",
    "if image1 is None or image2 is None or image3 is None:\n",
    "    print(\"Error loading images.\")\n",
    "else:\n",
    "    # Find corners and rank transforms for images 1, 2, and 3\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    gray3 = cv2.cvtColor(image3, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    hr1 = harris_response(*gaussian_smoothing(image_derivatives(gray1)))\n",
    "    hr2 = harris_response(*gaussian_smoothing(image_derivatives(gray2)))\n",
    "    hr3 = harris_response(*gaussian_smoothing(image_derivatives(gray3)))\n",
    "\n",
    "    corners1 = strongest_corners(hr1, non_maximum_suppression(hr1))\n",
    "    corners2 = strongest_corners(hr2, non_maximum_suppression(hr2))\n",
    "    corners3 = strongest_corners(hr3, non_maximum_suppression(hr3))\n",
    "\n",
    "    rank1 = rank_transform(gray1)\n",
    "    rank2 = rank_transform(gray2)\n",
    "    rank3 = rank_transform(gray3)\n",
    "\n",
    "    # Compute the distances between corners of images 1 and 2, and find best matches\n",
    "    distances12 = compute_distances(corners1, corners2, rank1, rank2)\n",
    "    matches12 = find_best_matches(distances12)\n",
    "\n",
    "    # Similarly, compute the distances between corners of images 2 and 3, and find best matches\n",
    "    distances23 = compute_distances(corners2, corners3, rank2, rank3)\n",
    "    matches23 = find_best_matches(distances23)\n",
    "\n",
    "    points1_3D = corners_to_3D_points(corners1[:, ::-1], depth1, K)\n",
    "    points2_3D = corners_to_3D_points(corners2[:, ::-1], depth2, K)\n",
    "    points3_3D = corners_to_3D_points(corners3[:, ::-1], depth3, K)\n",
    "\n",
    "\n",
    "    # Estimate the pose between images 1 and 2, and between images 2 and 3\n",
    "    R12, t12 = estimate_pose(matches12, points1_3D, points2_3D)\n",
    "    R23, t23 = estimate_pose(matches23, points2_3D, points3_3D)\n",
    "\n",
    "    points1_3D_full, colors1_full = get_colored_3d_points(image1, depth1, K)\n",
    "    points2_3D_full, colors2_full = get_colored_3d_points(image2, depth2, K)\n",
    "    points3_3D_full, colors3_full = get_colored_3d_points(image3, depth3, K)\n",
    "    \n",
    "    # added later\n",
    "    points1_3D_full = points1_3D_full[np.isfinite(points1_3D_full).all(axis=1)]\n",
    "    points2_3D_full = points2_3D_full[np.isfinite(points2_3D_full).all(axis=1)]\n",
    "    points3_3D_full = points3_3D_full[np.isfinite(points3_3D_full).all(axis=1)]\n",
    "\n",
    "    points1_transformed_full = transform_points(points1_3D_full, R12, t12)\n",
    "    points3_transformed_full = transform_points(points3_3D_full, R23.T, -R23.T @ t23)\n",
    "\n",
    "\n",
    "    # Transform the points from the third image to the coordinate system of the second image (new Code)\n",
    "    points3_transformed_to_2 = transform_points(points3_3D_full, R23.T, -R23.T @ t23)\n",
    "\n",
    "    # Transform the points from the second image (including the transformed points from the third image) to the coordinate system of the first image\n",
    "    points2_transformed_to_1 = transform_points(points2_3D_full, R12, t12)#(new code)\n",
    "    points3_transformed_to_1 = transform_points(points3_transformed_to_2, R12, t12)#(new code)    \n",
    "    \n",
    "    def save_points_to_ply(points, colors, filename):\n",
    "        num_points = len(points)\n",
    "        points_colors = np.hstack([points, colors]).reshape(-1, 6)\n",
    "\n",
    "        vertex = np.array([tuple(pc) for pc in points_colors],\n",
    "                          dtype=[('x', 'f4'), ('y', 'f4'), ('z', 'f4'), ('red', 'u1'), ('green', 'u1'), ('blue', 'u1')])\n",
    "\n",
    "        ply_header = PlyData([PlyElement.describe(vertex, 'vertex', comments=['vertices'])], text=True, byte_order='<')\n",
    "        ply_header.write(filename)\n",
    "    \n",
    "    save_points_to_ply(points1_3D_full, colors1_full, 'output11.ply')\n",
    "    save_points_to_ply(points2_3D_full, colors2_full, 'output22.ply')\n",
    "    save_points_to_ply(points3_3D_full, colors3_full, 'output33.ply')\n",
    "    \n",
    "    # Combine the transformed points from the second and third images with the points from the first image\n",
    "    combined_points = np.vstack([points1_3D_full, points2_transformed_to_1, points3_transformed_to_1])\n",
    "    \n",
    "    #final_output = np.vstack([points1_3D_full, points2_3D_full, points3_3D_full])\n",
    "    combined_colors = np.vstack([colors1_full, colors2_full, colors3_full])\n",
    "    \n",
    "    # Save the combined point cloud to a PLY file\n",
    "    save_points_to_ply(combined_points, combined_colors, 'combined_output11.ply')\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
